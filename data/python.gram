# PEG grammar for Python

# The subheader is formatted to include the filename, we must hence use double {}
# when we need teh python code to do some formatting.
@subheader'''
import itertools
import sys
import token
from typing import Any, List, Tuple, TypeVar, Union

# Singleton ast nodes, created once for efficiency
Load = ast.Load()
Store = ast.Store()
Del = ast.Del()

Node = TypeVar("Node")
FC = TypeVar("FC", ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)


class Parser(Parser):

    def check_version(self, min_version: Tuple[int, ...], error_msg: str, node: Node) -> Node:
        """Check that the python version is high enough for a rule to apply.

        """
        if sys.version_info >= min_version:
            return node
        else:
            raise SyntaxError(
                f"{{error_msg}} is only supported in Python {{min_version}} and above."
            )

    def raise_indentation_error(self, msg) -> None:
        """Raise an indentation error."""
        raise IndentationError(msg)

    def get_expr_name(self, node) -> str:
        """"""
        # See https://github.com/python/cpython/blob/master/Parser/pegen.c#L161
        return ""

    def set_expr_context(self, node, context):
        """Set the context (Load, Store, Del) of an ast node."""
        node.ctx = context
        return node

    def generate_ast_for_string(self, tokens):
        """Generate AST nodes for strings."""
        err_msg = ''
        try:
            m = ast.parse('(' + ' '.join([t.string for t in tokens]) + ')')
        except SyntaxError as e:
            err_msg = e.args[0]
            # Identify the line at which the error occurred to get a more
            # accurate line number
            for t in tokens:
                try:
                    m = ast.parse(t.string)
                except SyntaxError:
                    break

        # Avoid getting a triple nesting in the error report that does not
        # bring anything relevant to the traceback.
        if err_msg:
            return self.make_syntax_error(err_msg)

        return m.body[0].value

    def extract_import_level(self, tokens: List[tokenize.TokenInfo]) -> int:
        """Extract the relative import level from the tokens preceding the module name.

        '.' count for one and '...' for 3.

        """
        level = 0
        for t in tokens:
            if t.string == ".":
                level += 1
            else:
                level += 3
        return level

    def set_decorators(self,
        target: FC,
        decorators: list
    ) -> FC:
        """Set the decorators on a function or class definition."""
        target.decorator_list = decorators
        return target

    def get_comparison_ops(self, pairs):
        return [op for op, _ in pairs]

    def get_comparators(self, pairs):
        return [comp for _, comp in pairs]

    def set_arg_type_comment(self, arg, type_comment):
        if type_comment:
            arg.type_comment = type_comment
        return arg

    def make_arguments(self,
        pos_only: Optional[List[Tuple[ast.arg, None]]],
        pos_only_with_default: List[Tuple[ast.arg, Any]],
        param_no_default: Optional[List[Tuple[ast.arg, None]]],
        param_default: Optional[List[Tuple[ast.arg, Any]]],
        after_star: Optional[Tuple[Optional[ast.arg], List[Tuple[ast.arg, Any]], Optional[ast.arg]]]
    ) -> ast.arguments:
        """Build a function definition arguments."""
        if sys.version_info < (3, 9) and (pos_only or pos_only_with_default):
            self.make_syntax_error(
                "Positional only arguments are only supported in Python 3.9+")

        defaults = (
            [d for _, d in pos_only_with_default if d is not None]
            if pos_only_with_default else
            []
        )
        defaults += (
            [d for _, d in param_default if d is not None]
            if param_default else
            []
        )

        pos_only = pos_only or pos_only_with_default

        # Because we need to combine pos only with and without default even
        # the version with no default is a tuple
        pos_only = [p for p, _ in pos_only]
        params = (param_no_default or []) + ([p for p, _ in param_default] if param_default else [])

        # If after_star is None, make a default tuple
        after_star = after_star or (None, [], None)

        return ast.arguments(
            posonlyargs=pos_only,
            args=params,
            defaults=defaults,
            vararg=after_star[0],
            kwonlyargs=[p for p, _ in after_star[1]],
            kw_defaults=[d for _, d in after_star[1]],
            kwarg=after_star[2]
        )

'''

start: file

file[ast.Module]: a=[statements] ENDMARKER { ast.Module(body=a or [], type_ignores=[]) }
interactive[ast.Interactive]: a=statement_newline { ast.Interactive(body=a) }
eval[ast.Expression]: a=expressions NEWLINE* ENDMARKER { ast.Expression(body=a) }
func_type[ast.FunctionType]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { ast.FunctionType(argtypes=a, returns=b) }
fstring[ast.Expr]: star_expressions

# type_expressions allow */** but ignore them
type_expressions[list]:
    | a=','.expression+ ',' '*' b=expression ',' '**' c=expression { a + [b, c] }
    | a=','.expression+ ',' '*' b=expression { a + [b] }
    | a=','.expression+ ',' '**' b=expression { a + [b] }
    | '*' a=expression ',' '**' b=expression { [a, b] }
    | '*' a=expression { [a] }
    | '**' a=expression { [a] }
    | a=','.expression+ {a}

statements[list]: a=statement+ { list(itertools.chain(*a)) }
statement[list]: a=compound_stmt { [a] } | a=simple_stmts { a }
statement_newline[list]:
    | a=compound_stmt NEWLINE { [a] }
    | simple_stmt
    | NEWLINE { [ast.Pass()] }
    | ENDMARKER { None }
simple_stmts[list]:
    | a=simple_stmt !';' NEWLINE { [a] } # Not needed, there for speedup
    | a=';'.simple_stmt+ [';'] NEWLINE { a }
# NOTE: assignment MUST precede expression, else parsing a simple assignment
# will throw a SyntaxError.
simple_stmt (memo):
    | assignment
    | e=star_expressions { ast.Expr(value=e) }
    | &'return' return_stmt
    | &('import' | 'from') import_stmt
    | &'raise' raise_stmt
    | 'pass' { ast.Pass() }
    | &'del' del_stmt
    | &'yield' yield_stmt
    | &'assert' assert_stmt
    | 'break' { ast.Break() }
    | 'continue' { ast.Continue() }
    | &'global' global_stmt
    | &'nonlocal' nonlocal_stmt
compound_stmt:
    | &('def' | '@' | 'async') function_def
    | &'if' if_stmt
    | &('class' | '@') class_def
    | &('with' | 'async') with_stmt
    | &('for' | 'async') for_stmt
    | &'try' try_stmt
    | &'while' while_stmt

# NOTE: annotated_rhs may start with 'yield'; yield_expr must start with 'yield'
assignment:
    | a=NAME ':' b=expression c=['=' d=annotated_rhs { d }] {
        self.check_version(
            (3, 6),
            "Variable annotation syntax is",
            ast.AnnAssign(
                target=ast.Name(id=a.string, ctx=Store),
                annotation=b,
                value=c,
                simple=1,
            )
        ) }
    | a=('(' b=single_target ')' { b } | single_subscript_attribute_target) ':' b=expression c=['=' d=annotated_rhs { d }] {
        self.check_version(
            (3, 6),
            "Variable annotation syntax is",
            ast.AnnAssign(
                target=a,
                annotation=b,
                value=c,
                simple=0,
            )
        )
     }
    | a=(z=star_targets '=' { z })+ b=(yield_expr | star_expressions) !'=' tc=[TYPE_COMMENT] {
         ast.Assign(targets=a, value=b, type_comment=tc)
     }
    | a=single_target b=augassign ~ c=(yield_expr | star_expressions) {
        ast.AugAssign(target = a, op=b, value=c)
     }
    | invalid_assignment

augassign:
    | '+=' { ast.Add() }
    | '-=' { ast.Sub() }
    | '*=' { ast.Mult() }
    | '@=' { self.check_version((3, 5), "The '@' operator is", ast.MatMult()) }
    | '/=' { ast.Div() }
    | '%=' { ast.Mod() }
    | '&=' { ast.BitAnd() }
    | '|=' { ast.BitOr() }
    | '^=' { ast.BitXor() }
    | '<<=' { ast.LShift() }
    | '>>=' { ast.RShift() }
    | '**=' { ast.Pow() }
    | '//=' { ast.FloorDiv() }

global_stmt[ast.Global]: 'global' a=','.NAME+ {
    ast.Global(names=[n.string for n in a])
}
nonlocal_stmt[ast.Nonlocal]: 'nonlocal' a=','.NAME+ {
    ast.Nonlocal(names=[n.string for n in a])
}

yield_stmt[ast.Expr]: y=yield_expr { ast.Expr(value=y) }

assert_stmt[ast.Assert]: 'assert' a=expression b=[',' z=expression { z }] {
    ast.Assert(test=a, msg=b)
}

del_stmt[ast.Delete]:
    | 'del' a=del_targets &(';' | NEWLINE) { ast.Delete(targets=a) }
    | invalid_del_stmt

import_stmt[ast.Import]: import_name | import_from
import_name[ast.Import]: 'import' a=dotted_as_names { ast.Import(names=a) }
# note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS
import_from[ast.ImportFrom]:
    | 'from' a=('.' | '...')* b=dotted_name 'import' c=import_from_targets {
        ast.ImportFrom(module=b, names=c, level=self.extract_import_level(a))
     }
    | 'from' a=('.' | '...')+ 'import' b=import_from_targets {
        ast.ImportFrom(names=b, level=self.extract_import_level(a))
     }
import_from_targets[List[ast.alias]]:
    | '(' a=import_from_as_names [','] ')' { a }
    | import_from_as_names !','
    | '*' { [ast.alias(name="*", asname=None)] }
    | invalid_import_from_targets
import_from_as_names[List[ast.alias]]:
    | a=','.import_from_as_name+ { a }
import_from_as_name[ast.alias]:
    | a=NAME b=['as' z=NAME { z.string }] { ast.alias(name=a.string, asname=b) }
dotted_as_names[List[ast.alias]]: a=','.dotted_as_name+ { a }
dotted_as_name[ast.alias]:
    | a=dotted_name b=['as' z=NAME { z.string }] { ast.alias(name=a, asname=b) }
dotted_name[str]:
    | a=dotted_name '.' b=NAME { a + "." + b.string }
    | a=NAME { a.string }

if_stmt[ast.If]:
    | 'if' a=named_expression ':' b=block c=elif_stmt { ast.If(test=a, body=b, orelse=c or []) }
    | 'if' a=named_expression ':' b=block c=[else_block] { ast.If(test=a, body=b, orelse=c or []) }
elif_stmt[List[ast.If]]:
    | 'elif' a=named_expression ':' b=block c=elif_stmt { [ast.If(test=a, body=b, orelse=c)] }
    | 'elif' a=named_expression ':' b=block c=[else_block] { [ast.If(test=a, body=b, orelse=c or [])] }
else_block[list]: 'else' ':' b=block { b }

while_stmt[ast.While]:
    | 'while' a=named_expression ':' b=block c=[else_block] {
        ast.While(test=a, body=b, orelse=c or [])
     }

for_stmt[Union[ast.For, ast.AsyncFor]]:
    | 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        ast.For(target=t, iter=ex, body=b, orelse=el or [], type_comment=tc) }
    | 'async' 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        self.check_version(
            (3, 5),
            "Async for loops are",
            ast.AsyncFor(target=t, iter=ex, body=b, orelse=el or [], type_comment=tc)) }
    | invalid_for_target

with_stmt[Union[ast.With, ast.AsyncWith]]:
    | 'with' '(' a=','.with_item+ ','? ')' ':' b=block {
        ast.With(items=a, body=b) }
    | 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
        ast.With(items=a, body=b) }
    | 'async' 'with' '(' a=','.with_item+ ','? ')' ':' b=block {
       self.check_version(
           (3, 5),
           "Async with statements are",
           ast.AsyncWith(items=a, body=b)
        )
     }
    | 'async' 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
       self.check_version(
           (3, 5),
           "Async with statements are",
           ast.AsyncWith(items=a, body=b, type_comment=tc)
        )
     }
    | invalid_with_stmt

with_item[ast.withitem]:
    | e=expression 'as' t=star_target &(',' | ')' | ':') {
        ast.withitem(context_expr=e, optional_vars=t)
     }
    | invalid_with_item
    | e=expression { ast.withitem(context_expr=e, optional_vars=None) }

try_stmt[ast.Try]:
    | 'try' &&':' b=block f=finally_block { ast.Try(body=b, handlers=[], orelse=[], finalbody=f) }
    | 'try' &&':' b=block ex=except_block+ el=[else_block] f=[finally_block] {
        ast.Try(body=b, handlers=ex, orelse=el or [], finalbody=f or [])
     }
except_block[ast.ExceptHandler]:
    | 'except' e=expression t=['as' z=NAME { z.string }] ':' b=block {
        ast.ExceptHandler(type=e, name=t, body=b) }
    | 'except' ':' b=block { ast.ExceptHandler(type=None, name=None, body=b) }
    | invalid_except_block
finally_block[list]: 'finally' ':' a=block { a }

return_stmt[ast.Return]:
    | 'return' a=[star_expressions] { ast.Return(value=a) }

raise_stmt[ast.Raise]:
    | 'raise' a=expression b=['from' z=expression { z }] { ast.Raise(exc=a, cause=b) }
    | 'raise' { ast.Raise(exc=None, cause=None) }

function_def[Union[ast.FunctionDef, ast.AsyncFunctionDef]]:
    | d=decorators f=function_def_raw { self.set_decorators(f, d) }
    | f=function_def_raw {self.set_decorators(f, [])}

function_def_raw[Union[ast.FunctionDef, ast.AsyncFunctionDef]]:
    | 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] &&':' tc=[func_type_comment] b=block {
        ast.FunctionDef(
            name=n.string,
            args=params or self.make_arguments(None, [], None, [], None),
            returns=a,
            body=b,
            type_comment=tc
        )
     }
    | 'async' 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] &&':' tc=[func_type_comment] b=block {
       self.check_version(
            (3, 5),
            "Async functions are",
            ast.AsyncFunctionDef(
                name=n.string,
                args=params or self.make_arguments(None, [], None, [], None),
                returns=a,
                body=b,
                type_comment=tc
            )
        )
     }
func_type_comment:
    | NEWLINE t=TYPE_COMMENT &(NEWLINE INDENT) { t.string }  # Must be followed by indented block
    | invalid_double_type_comments
    | TYPE_COMMENT

params:
    | invalid_parameters
    | parameters

parameters[ast.arguments]:
    | a=slash_no_default b=param_no_default* c=param_with_default* d=[star_etc] {
        self.make_arguments(a, [], b, c, d)
     }
    | a=slash_with_default b=param_with_default* c=[star_etc] {
        self.make_arguments(None, a, None, b, c)
     }
    | a=param_no_default+ b=param_with_default* c=[star_etc] {
        self.make_arguments(None, [], a, b, c)
     }
    | a=param_with_default+ b=[star_etc] {
        self.make_arguments(None, [], None, a, b)
     }
    | a=star_etc { self.make_arguments(None, [], None, None, a) }

# Some duplication here because we can't write (',' | &')'),
# which is because we don't support empty alternatives (yet).
#

slash_no_default[List[Tuple[ast.arg, None]]]:
    | a=param_no_default+ '/' ',' { [(p, None) for p in a] }
    | a=param_no_default+ '/' &')' { [(p, None) for p in a] }
slash_with_default[List[Tuple[ast.arg, Any]]]:
    | a=param_no_default* b=param_with_default+ '/' ',' { a + b }
    | a=param_no_default* b=param_with_default+ '/' &')' { a + b }

star_etc[Tuple[Optional[ast.arg], List[Tuple[ast.arg, Any]], Optional[ast.arg]]]:
    | '*' a=param_no_default b=param_maybe_default* c=[kwds] { (a, b, c) }
    | '*' ',' b=param_maybe_default+ c=[kwds] { (None, b, c) }
    | a=kwds { (None, [], a) }
    | invalid_star_etc

kwds: '**' a=param_no_default { a }

# One parameter.  This *includes* a following comma and type comment.
#
# There are three styles:
# - No default
# - With default
# - Maybe with default
#
# There are two alternative forms of each, to deal with type comments:
# - Ends in a comma followed by an optional type comment
# - No comma, optional type comment, must be followed by close paren
# The latter form is for a final parameter without trailing comma.
#
param_no_default[ast.arg]:
    | a=param ',' tc=TYPE_COMMENT? { self.set_arg_type_comment(a, tc) }
    | a=param tc=TYPE_COMMENT? &')' { self.set_arg_type_comment(a, tc) }
param_with_default[Tuple[ast.arg, Any]]:
    | a=param c=default ',' tc=TYPE_COMMENT? { (self.set_arg_type_comment(a, tc), c) }
    | a=param c=default tc=TYPE_COMMENT? &')' { (self.set_arg_type_comment(a, tc), c) }
param_maybe_default[Tuple[ast.arg, Any]]:
    | a=param c=default? ',' tc=TYPE_COMMENT? { (self.set_arg_type_comment(a, tc), c) }
    | a=param c=default? tc=TYPE_COMMENT? &')' { (self.set_arg_type_comment(a, tc), c) }
param: a=NAME b=annotation? { ast.arg(arg=a.string, annotation=b) }

annotation: ':' a=expression { a }
default: '=' a=expression { a }

decorators: decorator+
decorator:
    | a=('@' f=dec_maybe_call NEWLINE { f }) { a }
    | a=('@' f=named_expression NEWLINE { f }) {
        self.check_version((3, 9), "Generic decorator are",  a)
     }
dec_maybe_call:
    | dn=dec_primary '(' z=arguments ')' {
        ast.Call(func=dn, args=z[0], keywords=z[1])
     }
    | dec_primary
dec_primary:
    | a=dec_primary '.' b=NAME { ast.Attribute(value=a, attr=b.string, ctx=Load) }
    | a=NAME { ast.Name(id=a.string, ctx=Load) }

class_def[ast.ClassDef]:
    | a=decorators b=class_def_raw { self.set_decorators(b, a) }
    | class_def_raw
class_def_raw[ast.ClassDef]:
    | 'class' a=NAME b=['(' z=[arguments] ')' { z }] &&':' c=block {
        ast.ClassDef(
            a.string,
            bases=b[0] if b else [],
            keywords=b[1] if b else [],
            body=c,
            decorator_list=[],
        )
     }

block[list] (memo):
    | NEWLINE INDENT a=statements DEDENT { a }
    | simple_stmts
    | invalid_block

expressions_list[list]: a=','.star_expression+ [','] { a }
star_expressions:
    | a=star_expression b=(',' c=star_expression { c })+ [','] {
        ast.Tuple(elts=[a] + b, ctx=Load) }
    | a=star_expression ',' { ast.Tuple(elts=[a], ctx=Load) }
    | star_expression
star_expression (memo):
    | '*' a=bitwise_or { ast.Starred(value=a, ctx=Load) }
    | expression

star_named_expressions: a=','.star_named_expression+ [','] { a }
star_named_expression:
    | '*' a=bitwise_or { ast.Starred(value=a, ctx=Load) }
    | named_expression
named_expression:
    | a=NAME ':=' ~ b=expression {
        ast.NamedExpr(target=ast.Name(id=a.string, ctx=Store), value=b)
     }
    | a=expression !':=' { a }
    | invalid_named_expression

annotated_rhs: yield_expr | star_expressions

expressions:
    | a=expression b=(',' c=expression { c })+ [','] {
        ast.Tuple(elts=[a] + b, ctx=Load) }
    | a=expression ',' { ast.Tuple(elts=[a], ctx=Load) }
    | expression
expression (memo):
    | a=disjunction 'if' b=disjunction 'else' c=expression {
        ast.IfExp(body=a, test=b, orelse=c)
     }
    | disjunction
    | lambdef

lambdef:
    | 'lambda' a=[lambda_params] ':' b=expression {
        ast.Lambda(args=a or self.make_arguments(None, [], None, [], (None, [], None)), body=b)
     }

lambda_params:
    | invalid_lambda_parameters
    | lambda_parameters

# lambda_parameters etc. duplicates parameters but without annotations
# or type comments, and if there's no comma after a parameter, we expect
# a colon, not a close parenthesis.  (For more, see parameters above.)
#
lambda_parameters[ast.arguments]:
    | a=lambda_slash_no_default b=lambda_param_no_default* c=lambda_param_with_default* d=[lambda_star_etc] {
        self.make_arguments(a, [], b, c, d)
     }
    | a=lambda_slash_with_default b=lambda_param_with_default* c=[lambda_star_etc] {
        self.make_arguments(None, a, None, b, c)
     }
    | a=lambda_param_no_default+ b=lambda_param_with_default* c=[lambda_star_etc] {
        self.make_arguments(None, [], a, b, c)
     }
    | a=lambda_param_with_default+ b=[lambda_star_etc] {
        self.make_arguments(None, [], None, a, b)
     }
    | a=lambda_star_etc { self.make_arguments(None, [], None, [], a) }

lambda_slash_no_default[List[Tuple[ast.arg, None]]]:
    | a=lambda_param_no_default+ '/' ',' { [(p, None) for p in a] }
    | a=lambda_param_no_default+ '/' &':' { [(p, None) for p in a] }
lambda_slash_with_default[List[Tuple[ast.arg, Any]]]:
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' ',' { a + b }
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' &':' { a + b }

lambda_star_etc[Tuple[Optional[ast.arg], List[Tuple[ast.arg, Any]], Optional[ast.arg]]]:
    | '*' a=lambda_param_no_default b=lambda_param_maybe_default* c=[lambda_kwds] {
       (a, b, c) }
    | '*' ',' b=lambda_param_maybe_default+ c=[lambda_kwds] {
        (None, b, c) }
    | a=lambda_kwds { (None, [], a) }
    | invalid_lambda_star_etc

lambda_kwds[ast.arg]: '**' a=lambda_param_no_default { a }

lambda_param_no_default[ast.arg]:
    | a=lambda_param ',' { a }
    | a=lambda_param &':' { a }
lambda_param_with_default[Tuple[ast.arg, Any]]:
    | a=lambda_param c=default ',' { (a, c) }
    | a=lambda_param c=default &':' { (a, c) }
lambda_param_maybe_default[Tuple[ast.arg, Any]]:
    | a=lambda_param c=default? ',' { (a, c) }
    | a=lambda_param c=default? &':' { (a, c) }
lambda_param[ast.arg]: a=NAME { ast.arg(arg=a.string, annotation=None) }

disjunction (memo):
    | a=conjunction b=('or' c=conjunction { c })+ { ast.BoolOp(op=ast.Or(), values=[a] + b) }
    | conjunction
conjunction (memo):
    | a=inversion b=('and' c=inversion { c })+ { ast.BoolOp(op=ast.And(), values=[a] + b) }
    | inversion
inversion (memo):
    | 'not' a=inversion { ast.UnaryOp(op=ast.Not(), operand=a) }
    | comparison
comparison:
    | a=bitwise_or b=compare_op_bitwise_or_pair+ {
        ast.Compare(left=a, ops=self.get_comparison_ops(b), comparators=self.get_comparators(b))
     }
    | bitwise_or

# Make a tuple of operator and comparator
compare_op_bitwise_or_pair:
    | eq_bitwise_or
    | noteq_bitwise_or
    | lte_bitwise_or
    | lt_bitwise_or
    | gte_bitwise_or
    | gt_bitwise_or
    | notin_bitwise_or
    | in_bitwise_or
    | isnot_bitwise_or
    | is_bitwise_or
eq_bitwise_or: '==' a=bitwise_or { (ast.Eq(), a) }
# Do not support the Barry as BDFL <> for not eq
noteq_bitwise_or[tuple]:
    | '!=' a=bitwise_or { (ast.NotEq(), a) }
lte_bitwise_or: '<=' a=bitwise_or { (ast.LtE(), a) }
lt_bitwise_or: '<' a=bitwise_or { (ast.Lt(), a) }
gte_bitwise_or: '>=' a=bitwise_or { (ast.GtE(), a) }
gt_bitwise_or: '>' a=bitwise_or { (ast.Gt(), a) }
notin_bitwise_or: 'not' 'in' a=bitwise_or { (ast.NotIn(), a) }
in_bitwise_or: 'in' a=bitwise_or { (ast.In(), a) }
isnot_bitwise_or: 'is' 'not' a=bitwise_or { (ast.IsNot(), a) }
is_bitwise_or: 'is' a=bitwise_or { (ast.Is(), a) }

bitwise_or:
    | a=bitwise_or '|' b=bitwise_xor { ast.BinOp(left=a, op=ast.BitOr(), right=b) }
    | bitwise_xor
bitwise_xor:
    | a=bitwise_xor '^' b=bitwise_and { ast.BinOp(left=a, op=ast.BitXor(), right=b) }
    | bitwise_and
bitwise_and:
    | a=bitwise_and '&' b=shift_expr { ast.BinOp(left=a, op=ast.BitAnd(), right=b) }
    | shift_expr
shift_expr:
    | a=shift_expr '<<' b=sum { ast.BinOp(left=a, op=ast.LShift(), right=b) }
    | a=shift_expr '>>' b=sum { ast.BinOp(left=a, op=ast.RShift(), right=b) }
    | sum

sum:
    | a=sum '+' b=term { ast.BinOp(left=a, op=ast.Add(), right=b) }
    | a=sum '-' b=term { ast.BinOp(left=a, op=ast.Sub(), right=b) }
    | term
term:
    | a=term '*' b=factor { ast.BinOp(left=a, op=ast.Mult(), right=b) }
    | a=term '/' b=factor { ast.BinOp(left=a, op=ast.Div(), right=b) }
    | a=term '//' b=factor { ast.BinOp(left=a, op=ast.FloorDiv(), right=b) }
    | a=term '%' b=factor { ast.BinOp(left=a, op=ast.Mod(), right=b) }
    | a=term '@' b=factor {
        self.check_version((3, 5), "The '@' operator is", ast.BinOp(left=a, op=ast.MatMult(), right=b))
     }
    | factor
factor (memo):
    | '+' a=factor { ast.UnaryOp(op=ast.UAdd(), operand=a) }
    | '-' a=factor { ast.UnaryOp(op=ast.USub(), operand=a) }
    | '~' a=factor { ast.UnaryOp(op=ast.Invert(), operand=a) }
    | power
power:
    | a=await_primary '**' b=factor { ast.BinOp(left=a, op=ast.Pow(), right=b) }
    | await_primary
await_primary (memo):
    | 'await' a=primary { self.check_version((3, 5), "Await expressions are", ast.Await(a)) }
    | primary
primary:
    | invalid_primary  # must be before 'primay genexp' because of invalid_genexp
    | a=primary '.' b=NAME { ast.Attribute(value=a, attr=b.string, ctx=Load) }
    | a=primary b=genexp { ast.Call(func=a, args=[b], keywords=[]) }
    | a=primary '(' b=[arguments] ')' {
        ast.Call(
            func=a,
            args=b[0] if b else [],
            keywords=b[1] if b else [],
        )
     }
    | a=primary '[' b=slices ']' { ast.Subscript(value=a, slice=b, ctx=Load) }
    | atom

slices:
    | a=slice !',' { a }
    | a=','.slice+ [','] { ast.Tuple(elts=a, ctx=Load) }
slice:
    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] { ast.Slice(lower=a, upper=b, step=c) }
    | a=expression { a }
atom:
    | a=NAME { ast.Name(id=a.string, ctx=Load) }
    | 'True' { ast.NameConstant(True) }
    | 'False' { ast.NameConstant(False) }
    | 'None' { ast.NameConstant(None) }
    | &STRING strings
    | a=NUMBER { ast.Num(n=ast.literal_eval(a.string)) }
    | &'(' (tuple | group | genexp)
    | &'[' (list | listcomp)
    | &'{' (dict | set | dictcomp | setcomp)
    | '...' { ast.Ellipsis() }

strings[ast.Str] (memo): a=STRING+ { self.generate_ast_for_string(a) }
list[ast.List]:
    | '[' a=[star_named_expressions] ']' { ast.List(elts=a or [], ctx=Load) }
listcomp[ast.ListComp]:
    | '[' a=named_expression b=for_if_clauses ']' { ast.ListComp(elt=a, generators=b) }
    | invalid_comprehension
tuple[ast.Tuple]:
    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] { [y] + (z or []) } ] ')' {
        ast.Tuple(elts=a or [], ctx=Load)
     }
group:
    | '(' a=(yield_expr | named_expression) ')' { a }
    | invalid_group
genexp[ast.GeneratorExp]:
    | '(' a=named_expression b=for_if_clauses ')' { ast.GeneratorExp(elt=a, generators=b) }
    | invalid_comprehension
set[ast.Set]: '{' a=star_named_expressions '}' { ast.Set(elts=a) }
setcomp[ast.SetComp]:
    | '{' a=named_expression b=for_if_clauses '}' { ast.SetComp(elt=a, generators=b) }
    | invalid_comprehension
dict[ast.Dict]:
    | '{' a=[double_starred_kvpairs] '}' {
        ast.Dict(keys=[kv[0] for kv in (a or [])], values=[kv[1] for kv in (a or [])])
     }
dictcomp[ast.DictComp]:
    | '{' a=kvpair b=for_if_clauses '}' { ast.DictComp(key=a[0], value=a[1], generators=b) }
    | invalid_dict_comprehension
double_starred_kvpairs[list]: a=','.double_starred_kvpair+ [','] { a }
double_starred_kvpair:
    | '**' a=bitwise_or { (None, a) }
    | kvpair
kvpair[tuple]: a=expression ':' b=expression { (a, b) }
for_if_clauses[List[ast.comprehension]]:
    | a=for_if_clause+ { a }
for_if_clause[ast.comprehension]:
    | 'async' 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction { z })* {
        self.check_version(
            (3, 6),
            "Async comprehensions are",
            ast.comprehension(target=a, iter=b, ifs=c, is_async=1)
        )
     }
    | 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction { z })* {
       ast.comprehension(target=a, iter=b, ifs=c, is_async=0) }
    | invalid_for_target

yield_expr:
    | 'yield' 'from' a=expression { ast.YieldFrom(value=a) }
    | 'yield' a=[star_expressions] { ast.Yield(value=a) }

arguments[Tuple[list, list]] (memo):
    | a=args [','] &')' { a }
    | invalid_arguments
args[Tuple[list, list]]:
    | a=','.(starred_expression | named_expression !'=')+ b=[',' k=kwargs {k}] {
        (a + ([e for e in b if isinstance(e, ast.Starred)] if b else []),
         ([e for e in b if not isinstance(e, ast.Starred)] if b else [])
        )
     }
    | a=kwargs {
        ([e for e in a if isinstance(e, ast.Starred)],
         [e for e in a if not isinstance(e, ast.Starred)])
    }
kwargs[list]:
    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ { a + b }
    | ','.kwarg_or_starred+
    | ','.kwarg_or_double_starred+
starred_expression:
    | '*' a=expression { ast.Starred(value=a, ctx=Load) }
kwarg_or_starred:
    | a=NAME '=' b=expression { ast.keyword(arg=a.string, value=b) }
    | a=starred_expression { a }
    | invalid_kwarg
kwarg_or_double_starred:
    | a=NAME '=' b=expression { ast.keyword(arg=a.string, value=b) }
    | '**' a=expression { ast.keyword(arg=None, value=a) }
    | invalid_kwarg

# NOTE: star_targets may contain *bitwise_or, targets may not.
star_targets:
    | a=star_target !',' { a }
    | a=star_target b=(',' c=star_target { c })* [','] {
        ast.Tuple(elts=[a] + b, ctx=Store)
     }
star_targets_list_seq[list]: a=','.star_target+ [','] { a }
star_targets_tuple_seq[list]:
    | a=star_target b=(',' c=star_target { c })+ [','] { [a] + b }
    | a=star_target ',' { [a] }
star_target (memo):
    | '*' a=(!'*' star_target) {
        ast.Starred(value=self.set_expr_context(a, Store), ctx=Store)
     }
    | target_with_star_atom
target_with_star_atom (memo):
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Store) }
    | star_atom
star_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=target_with_star_atom ')' { self.set_expr_context(a, Store) }
    | '(' a=[star_targets_tuple_seq] ')' { ast.Tuple(elts=a, ctx=Store) }
    | '[' a=[star_targets_list_seq] ']' {  ast.List(elts=a, ctx=Store) }

single_target:
    | single_subscript_attribute_target
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=single_target ')' { a }
single_subscript_attribute_target:
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Store) }

del_targets: a=','.del_target+ [','] { a }
del_target (memo):
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Del) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Del) }
    | del_t_atom
del_t_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Del) }
    | '(' a=del_target ')' { self.set_expr_context(a, Del) }
    | '(' a=[del_targets] ')' { ast.Tuple(elts=a, ctx=Del) }
    | '[' a=[del_targets] ']' { ast.List(elts=a, ctx=Del) }

targets: a=','.target+ [','] { a }
target (memo):
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Store) }
    | t_atom
t_primary:
    | a=t_primary '.' b=NAME &t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Load) }
    | a=t_primary '[' b=slices ']' &t_lookahead { ast.Subscript(value=a, slice=b, ctx=Load) }
    | a=t_primary b=genexp &t_lookahead { ast.Call(func=a, args=[b], keywords=[]) }
    | a=t_primary '(' b=[arguments] ')' &t_lookahead {
        ast.Call(
            func=a,
            args=b[0] if b else [],
            keywords=b[1] if b else [],
        )
     }
    | a=atom &t_lookahead { a }
t_lookahead: '(' | '[' | '.'
t_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=target ')' { self.set_expr_context(a, Store) }
    | '(' b=[targets] ')' { ast.Tuple(elts=b, ctx=Store) }
    | '[' b=[targets] ']' { ast.List(elts=b, ctx=Store) }


# From here on, there are rules for invalid syntax with specialised error messages
invalid_arguments:
    | args ',' '*' {
        self.make_syntax_error(
            "iterable argument unpacking follows keyword argument unpacking"
        )
     }
    | a=expression for_if_clauses ',' [args | expression for_if_clauses] {
        self.make_syntax_error("Generator expression must be parenthesized")
     }
    | a=args for_if_clauses {
        self.make_syntax_error("Generator expression must be parenthesized")
     }
    | args ',' a=expression for_if_clauses {
        self.make_syntax_error("Generator expression must be parenthesized") }
    | a=args ',' args {
        self.make_syntax_error(
            "positional argument follows keyword argument unpacking"
            if isinstance(args[1][-1], ast.Starred) else
            "positional argument follows keyword argument",
        )
     }
invalid_kwarg:
    | expression a='=' {
        self.make_syntax_error(
            "expression cannot contain assignment, perhaps you meant \"==\"?",
        )
     }
invalid_named_expression:
    | a=expression ':=' expression {
        self.make_syntax_error(
            f"cannot use assignment expressions with {self.get_expr_name(a)}",
        )
     }
invalid_assignment:
    | a=invalid_ann_assign_target ':' expression {
        self.make_syntax_error(
            "only single target (not {self.get_expr_name(a)}) can be annotated",
        )
     }
    | a=star_named_expression ',' star_named_expressions* ':' expression {
        self.make_syntax_error("only single target (not tuple) can be annotated") }
    | a=expression ':' expression {
        self.make_syntax_error("illegal target for annotation") }
    | (star_targets '=')* a=star_expressions '=' {
        self.make_syntax_error("cannot assign to {self.get_expr_name(a)}")
     }
    | (star_targets '=')* a=yield_expr '=' {
        self.make_syntax_error( "assignment to yield expression not possible")
     }
    | a=star_expressions augassign (yield_expr | star_expressions) {
        self.make_syntax_error(
            "'{self.get_expr_name(a)' is an illegal expression for augmented assignment",
        )
     }
invalid_ann_assign_target:
    | list
    | tuple
    | '(' a=invalid_ann_assign_target ')' { a }
invalid_del_stmt:
    | 'del' a=star_expressions {
        self.make_syntax_error("cannot delete {self.get_expr_name(a)}") }
invalid_block:
    | NEWLINE !INDENT { self.raise_indentation_error("expected an indented block") }
invalid_primary:
    | primary a='{' {
        self.make_syntax_error("invalid syntax")
     }
invalid_comprehension:
    | ('[' | '(' | '{') a=starred_expression for_if_clauses {
        self.make_syntax_error("iterable unpacking cannot be used in comprehension")
     }
invalid_dict_comprehension:
    | '{' a='**' bitwise_or for_if_clauses '}' {
        self.make_syntax_error("dict unpacking cannot be used in dict comprehension")
     }
invalid_parameters:
    | param_no_default* (slash_with_default | param_with_default+) param_no_default {
        self.make_syntax_error("non-default argument follows default argument")
     }
invalid_lambda_parameters:
    | lambda_param_no_default* (lambda_slash_with_default | lambda_param_with_default+) lambda_param_no_default {
        self.make_syntax_error("non-default argument follows default argument")
     }
invalid_star_etc:
    | '*' (')' | ',' (')' | '**')) {
        self.make_syntax_error("named arguments must follow bare *")
     }
    | '*' ',' TYPE_COMMENT { self.make_syntax_error("bare * has associated type comment") }
invalid_lambda_star_etc:
    | '*' (':' | ',' (':' | '**')) {
        self.make_syntax_error("named arguments must follow bare *")
     }
invalid_double_type_comments:
    | TYPE_COMMENT NEWLINE TYPE_COMMENT NEWLINE INDENT {
        self.make_syntax_error("Cannot have two type comments on def") }
invalid_with_item:
    | expression 'as' a=expression {
        self.make_syntax_error("cannot assign to {self.get_expr_name(a)}")
     }

invalid_for_target:
    | 'async'? 'for' a=star_expressions {
        self.make_syntax_error("cannot assign to {self.get_expr_name(a)}")
     }

invalid_group:
    | '(' a=starred_expression ')' {
        self.make_syntax_error("can't use starred expression here")
     }
invalid_import_from_targets:
    | import_from_as_names ',' {
        self.make_syntax_error("trailing comma not allowed without surrounding parentheses")
     }

invalid_with_stmt:
    | ['async'] 'with' ','.(expression ['as' star_target])+ &&':'
    | ['async'] 'with' '(' ','.(expressions ['as' star_target])+ ','? ')' &&':'

invalid_except_block:
    | 'except' a=expression ',' expressions ['as' NAME ] ':' {
        self.make_syntax_error("exception group must be parenthesized")
     }
    | 'except' expression ['as' NAME ] &&':'
    | 'except' &&':'
