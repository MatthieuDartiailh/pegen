# PEG grammar for Python

@subheader'''
from typing import List

# Singleton ast nodes, created once for efficiency
Load = ast.Load()
Store = ast.Store()

class Parser(Parser):

    def set_expr_context(node, context):
        pass

    def make_arguments():
        pass

'''

start: file  # CHANGED: Not present in the original

file[ast.Module]: a=[statements] ENDMARKER { ast.Module(body=a, type_ignores=[]) }
#interactive[mod_ty]: a=statement_newline { Interactive(a, p->arena) }
eval[ast.Expression]: a=expressions NEWLINE* ENDMARKER { ast.Expression(body=a) }
#func_type[mod_ty]: '(' a=[type_expressions] ')' '->' b=expression NEWLINE* ENDMARKER { FunctionType(a, b, p->arena) }
fstring[expr_ty]: star_expressions

# type_expressions allow */** but ignore them
type_expressions[list]:
    | a=','.expression+ ',' '*' b=expression ',' '**' c=expression { a + [b, c] }
    | a=','.expression+ ',' '*' b=expression { a + [b] }
    | a=','.expression+ ',' '**' b=expression { a + [b] }
    | '*' a=expression ',' '**' b=expression { [a, b] }
    | '*' a=expression { [a] }
    | '**' a=expression { [a] }
    | a=','.expression+ {a}

statements: a=statement+ { (asdl_stmt_seq*)_PyPegen_seq_flatten(p, a) }
statement[list]: a=compound_stmt { [a] } | a=simple_stmt { a }
statement_newline[list]:
    | a=compound_stmt NEWLINE { [a] }
    | simple_stmt
    | NEWLINE { [ast.Pass()] }
    | ENDMARKER { _PyPegen_interactive_exit(p) }
simple_stmt[list]:
    | a=small_stmt !';' NEWLINE { [a] } # Not needed, there for speedup
    | a=';'.small_stmt+ [';'] NEWLINE { a }
# NOTE: assignment MUST precede expression, else parsing a simple assignment
# will throw a SyntaxError.
small_stmt[stmt_ty] (memo):
    | assignment
    | e=star_expressions { ast.Expr(value=e) }
    | &'return' return_stmt
    | &('import' | 'from') import_stmt
    | &'raise' raise_stmt
    | 'pass' { ast.Pass() }
    | &'del' del_stmt
    | &'yield' yield_stmt
    | &'assert' assert_stmt
    | 'break' { ast.Break() }
    | 'continue' { ast.Continue() }
    | &'global' global_stmt
    | &'nonlocal' nonlocal_stmt
compound_stmt[stmt_ty]:
    | &('def' | '@' | ASYNC) function_def
    | &'if' if_stmt
    | &('class' | '@') class_def
    | &('with' | ASYNC) with_stmt
    | &('for' | ASYNC) for_stmt
    | &'try' try_stmt
    | &'while' while_stmt

# NOTE: annotated_rhs may start with 'yield'; yield_expr must start with 'yield'
assignment:
    | a=NAME ':' b=expression c=['=' d=annotated_rhs { d }] {
        CHECK_VERSION(
            6,
            "Variable annotation syntax is",
            _Py_AnnAssign(CHECK(_PyPegen_set_expr_context(p, a, Store)), b, c, 1, EXTRA)
        ) }
    | a=('(' b=single_target ')' { b }
         | single_subscript_attribute_target) ':' b=expression c=['=' d=annotated_rhs { d }] {
        CHECK_VERSION(6, "Variable annotations syntax is", _Py_AnnAssign(a, b, c, 0, EXTRA)) }
    | a=(z=star_targets '=' { z })+ b=(yield_expr | star_expressions) !'=' tc=[TYPE_COMMENT] {
         ast.Assign(targets=a, value=b, type_comment=NEW_TYPE_COMMENT(p, tc)) }
    | a=single_target b=augassign ~ c=(yield_expr | star_expressions) {
         b.target = a; b.value = c; b }
    | invalid_assignment

augassign[AugOperator*]:
    | '+=' { ast.AugAssign(op=ast.Add()) }
    | '-=' { ast.AugAssign(op=ast.Sub()) }
    | '*=' { ast.AugAssign(op=ast.Mult()) }
    # XXX
    | '@=' { CHECK_VERSION(5, "The '@' operator is", _PyPegen_augoperator(p, MatMult)) }
    | '/=' { ast.AugAssign(op=ast.Div()) }
    | '%=' { ast.AugAssign(op=ast.Mod()) }
    | '&=' {ast.AugAssign(op=ast.BitAnd()) }
    | '|=' { ast.AugAssign(op=ast.BitOr()) }
    | '^=' { ast.AugAssign(op=ast.BitXor()) }
    | '<<=' { ast.AugAssign(op=ast.LShift()) }
    | '>>=' { ast.AugAssign(op=ast.RShift()) }
    | '**=' { ast.AugAssign(op=ast.Pow()) }
    | '//=' { ast.AugAssign(op=ast.FloorDiv()) }

global_stmt[stmt_ty]: 'global' a=','.NAME+ {
    ast.Global(names=[n.string for n in a])
}
nonlocal_stmt[stmt_ty]: 'nonlocal' a=','.NAME+ {
    ast.NonLocal(names=[n.string for n in a])
}

yield_stmt[stmt_ty]: y=yield_expr { ast.Expr(value=y)) }

assert_stmt[stmt_ty]: 'assert' a=expression b=[',' z=expression { z }] {
    ast.Assert(test=a, message=b)
}

del_stmt[stmt_ty]:
    | 'del' a=del_targets &(';' | NEWLINE) { ast.Delete(targets=a) }
    | invalid_del_stmt

import_stmt[stmt_ty]: import_name | import_from
import_name[stmt_ty]: 'import' a=dotted_as_names { ast.Import(names=a) }
# note below: the ('.' | '...') is necessary because '...' is tokenized as ELLIPSIS
import_from[stmt_ty]:
    | 'from' a=('.' | '...')* b=dotted_name 'import' c=import_from_targets {
        ast.Import(module=b, names=c, level=# XXX) }
    | 'from' a=('.' | '...')+ 'import' b=import_from_targets {
        ast.Import(names=b, level=# XXX) }
import_from_targets[asdl_alias_seq*]:
    | '(' a=import_from_as_names [','] ')' { a }
    | import_from_as_names !','
    | '*' { (asdl_alias_seq*)_PyPegen_singleton_seq(p, CHECK(_PyPegen_alias_for_star(p))) }
    | invalid_import_from_targets
import_from_as_names[asdl_alias_seq*]:
    | a[asdl_alias_seq*]=','.import_from_as_name+ { a }
import_from_as_name[alias_ty]:
    | a=NAME b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,
                                               (b) ? ((expr_ty) b)->v.Name.id : NULL,
                                               p->arena) }
dotted_as_names: a=','.dotted_as_name+ { a }
dotted_as_name:
    | a=dotted_name b=['as' z=NAME { z }] { _Py_alias(a->v.Name.id,
                                                      (b) ? ((expr_ty) b)->v.Name.id : NULL,
                                                      p->arena) }
dotted_name[expr_ty]:
    | a=dotted_name '.' b=NAME { _PyPegen_join_names_with_dot(p, a, b) }
    | NAME

if_stmt:
    | 'if' a=named_expression ':' b=block c=elif_stmt { ast.If(test=a, body=b, orelse=elif_stmt) }
    | 'if' a=named_expression ':' b=block c=[else_block] { ast.If(test=a, body=b, orelse=[c] if c else []) }
elif_stmt:
    | 'elif' a=named_expression ':' b=block c=elif_stmt { [ast.If(test=a, body=b)] + c }
    | 'elif' a=named_expression ':' b=block c=[else_block] { [ast.If(test=a, body=b, orelse=[c] if c else [])] }
else_block: 'else' ':' b=block { b }

while_stmt[stmt_ty]:
    | 'while' a=named_expression ':' b=block c=[else_block] { ast.While(test=a, body=block, orelse=[c] if c else []) }

for_stmt:
    | 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        ast.For(target=t, iter=ex, body=b, orelse=[el] if el else [], type_comment=tc) }
    | ASYNC 'for' t=star_targets 'in' ~ ex=star_expressions ':' tc=[TYPE_COMMENT] b=block el=[else_block] {
        CHECK_VERSION(5, "Async for loops are", _Py_AsyncFor(t, ex, b, el, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
    | invalid_for_target

with_stmt:
    | 'with' '(' a=','.with_item+ ','? ')' ':' b=block {
        _Py_With(a, b, NULL, EXTRA) }
    | 'with' a=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
        _Py_With(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | ASYNC 'with' '(' a[asdl_withitem_seq*]=','.with_item+ ','? ')' ':' b=block {
       CHECK_VERSION(5, "Async with statements are", _Py_AsyncWith(a, b, NULL, EXTRA)) }
    | ASYNC 'with' a[asdl_withitem_seq*]=','.with_item+ ':' tc=[TYPE_COMMENT] b=block {
       CHECK_VERSION(5, "Async with statements are", _Py_AsyncWith(a, b, NEW_TYPE_COMMENT(p, tc), EXTRA)) }
with_item[withitem_ty]:
    | e=expression 'as' t=star_target &(',' | ')' | ':') { _Py_withitem(e, t, p->arena) }
    | invalid_with_item
    | e=expression { _Py_withitem(e, NULL, p->arena) }

try_stmt[ast.Try]:
    | 'try' ':' b=block f=finally_block { ast.Try(body=b, finalbody=f) }
    | 'try' ':' b=block ex=except_block+ el=[else_block] f=[finally_block] {
        ast.Try(body=block, handlers=ex, orelse=el, finalbody=f)
     }
except_block[ast.ExceptHandler]:
    | 'except' e=expression t=['as' z=NAME { z }] ':' b=block {
        ast.ExceptHandler(type=e, name=t.string, body=block) }
    | 'except' ':' b=block { ast.ExceptHandler(type=None, name=None, body=block) }
finally_block[list]: 'finally' ':' a=block { a }

return_stmt:
    | 'return' a=[star_expressions] { ast.Return(value=a) }

raise_stmt[stmt_ty]:
    | 'raise' a=expression b=['from' z=expression { z }] { ast.Raise(exc=a, cause=b) }
    | 'raise' { ast.Raise(exc=None, cause=None) }

function_def[stmt_ty]:
    | d=decorators f=function_def_raw { _PyPegen_function_def_decorators(p, d, f) }
    | function_def_raw

function_def_raw[stmt_ty]:
    | 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] ':' tc=[func_type_comment] b=block {
        _Py_FunctionDef(n->v.Name.id,
                        (params) ? params : CHECK(_PyPegen_empty_arguments(p)),
                        b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA) }
    | ASYNC 'def' n=NAME '(' params=[params] ')' a=['->' z=expression { z }] ':' tc=[func_type_comment] b=block {
        CHECK_VERSION(
            5,
            "Async functions are",
            _Py_AsyncFunctionDef(n->v.Name.id,
                            (params) ? params : CHECK(_PyPegen_empty_arguments(p)),
                            b, NULL, a, NEW_TYPE_COMMENT(p, tc), EXTRA)
        ) }
func_type_comment:
    | NEWLINE t=TYPE_COMMENT &(NEWLINE INDENT) { t }  # Must be followed by indented block
    | invalid_double_type_comments
    | TYPE_COMMENT

params:
    | invalid_parameters
    | parameters

parameters[arguments_ty]:
    | a=slash_no_default b[asdl_arg_seq*]=param_no_default* c=param_with_default* d=[star_etc] {
        _PyPegen_make_arguments(p, a, NULL, b, c, d) }
    | a=slash_with_default b=param_with_default* c=[star_etc] {
        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }
    | a[asdl_arg_seq*]=param_no_default+ b=param_with_default* c=[star_etc] {
        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }
    | a=param_with_default+ b=[star_etc] { _PyPegen_make_arguments(p, NULL, NULL, NULL, a, b)}
    | a=star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, a) }

# Some duplication here because we can't write (',' | &')'),
# which is because we don't support empty alternatives (yet).
#
slash_no_default:
    | a=param_no_default+ '/' ',' { a }
    | a=param_no_default+ '/' &')' { a }
slash_with_default[SlashWithDefault*]:
    | a=param_no_default* b=param_with_default+ '/' ',' { _PyPegen_slash_with_default(p, (asdl_arg_seq *)a, b) }
    | a=param_no_default* b=param_with_default+ '/' &')' { _PyPegen_slash_with_default(p, (asdl_arg_seq *)a, b) }

star_etc[StarEtc*]:
    | '*' a=param_no_default b=param_maybe_default* c=[kwds] {
        _PyPegen_star_etc(p, a, b, c) }
    | '*' ',' b=param_maybe_default+ c=[kwds] {
        _PyPegen_star_etc(p, NULL, b, c) }
    | a=kwds { _PyPegen_star_etc(p, NULL, NULL, a) }
    | invalid_star_etc

kwds: '**' a=param_no_default { a }

# One parameter.  This *includes* a following comma and type comment.
#
# There are three styles:
# - No default
# - With default
# - Maybe with default
#
# There are two alternative forms of each, to deal with type comments:
# - Ends in a comma followed by an optional type comment
# - No comma, optional type comment, must be followed by close paren
# The latter form is for a final parameter without trailing comma.
#
param_no_default[arg_ty]:
    | a=param ',' tc=TYPE_COMMENT? { _PyPegen_add_type_comment_to_arg(p, a, tc) }
    | a=param tc=TYPE_COMMENT? &')' { _PyPegen_add_type_comment_to_arg(p, a, tc) }
param_with_default[NameDefaultPair*]:
    | a=param c=default ',' tc=TYPE_COMMENT? { _PyPegen_name_default_pair(p, a, c, tc) }
    | a=param c=default tc=TYPE_COMMENT? &')' { _PyPegen_name_default_pair(p, a, c, tc) }
param_maybe_default[NameDefaultPair*]:
    | a=param c=default? ',' tc=TYPE_COMMENT? { _PyPegen_name_default_pair(p, a, c, tc) }
    | a=param c=default? tc=TYPE_COMMENT? &')' { _PyPegen_name_default_pair(p, a, c, tc) }
param: a=NAME b=annotation? { ast.arg(arg=a.string, annotation=b) }

annotation: ':' a=expression { a }
default: '=' a=expression { a }

decorators: a=('@' f=named_expression NEWLINE { f })+ { a }

class_def[stmt_ty]:
    | a=decorators b=class_def_raw { _PyPegen_class_def_decorators(p, a, b) }
    | class_def_raw
class_def_raw[stmt_ty]:
    | 'class' a=NAME b=['(' z=[arguments] ')' { z }] ':' c=block {
        _Py_ClassDef(a->v.Name.id,
                     (b) ? ((expr_ty) b)->v.Call.args : NULL,
                     (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
                     c, NULL, EXTRA) }

block[list] (memo):
    | NEWLINE INDENT a=statements DEDENT { a }
    | simple_stmt
    | invalid_block

expressions_list: a=','.star_expression+ [','] { a }
star_expressions:
    | a=star_expression b=(',' c=star_expression { c })+ [','] {
        ast.Tuple(elts=[a] + b, ctx=Load) }
    | a=star_expression ',' { ast.Tuple(elts=[a], ctx=Load) }
    | star_expression
star_expression (memo):
    | '*' a=bitwise_or { ast.Starred(value=a, ctx=Load) }
    | expression

star_named_expressions: a=','.star_named_expression+ [','] { a }
star_named_expression:
    | '*' a=bitwise_or { ast.Starred(value=a, ctx=Load) }
    | named_expression
named_expression:
    | a=NAME ':=' ~ b=expression { ast.NamedExpr(target=ast.Name(id=a.string, ctx=Store), value=b) }
    | expression !':='
    | invalid_named_expression

annotated_rhs: yield_expr | star_expressions

expressions:
    | a=expression b=(',' c=expression { c })+ [','] {
        ast.Tuple(elts=[a] + b, ctx=Load) }
    | a=expression ',' { ast.Tuple(elts=[a], ctx=Load) }
    | expression
expression (memo):
    | a=disjunction 'if' b=disjunction 'else' c=expression { ast.IfExp(body=a, test=b, orelse=c) }
    | disjunction
    | lambdef

lambdef:
    | 'lambda' a=[lambda_params] ':' b=expression { ast.Lambda(args=a or self.make_args([]), body=b) }

lambda_params:
    | invalid_lambda_parameters
    | lambda_parameters

# lambda_parameters etc. duplicates parameters but without annotations
# or type comments, and if there's no comma after a parameter, we expect
# a colon, not a close parenthesis.  (For more, see parameters above.)
#
lambda_parameters[ast.arguments]:
    | a=lambda_slash_no_default b[asdl_arg_seq*]=lambda_param_no_default* c=lambda_param_with_default* d=[lambda_star_etc] {
        _PyPegen_make_arguments(p, a, NULL, b, c, d) }
    | a=lambda_slash_with_default b=lambda_param_with_default* c=[lambda_star_etc] {
        _PyPegen_make_arguments(p, NULL, a, NULL, b, c) }
    | a[asdl_arg_seq*]=lambda_param_no_default+ b=lambda_param_with_default* c=[lambda_star_etc] {
        _PyPegen_make_arguments(p, NULL, NULL, a, b, c) }
    | a=lambda_param_with_default+ b=[lambda_star_etc] { _PyPegen_make_arguments(p, NULL, NULL, NULL, a, b)}
    | a=lambda_star_etc { _PyPegen_make_arguments(p, NULL, NULL, NULL, NULL, a) }

lambda_slash_no_default[asdl_arg_seq*]:
    | a[asdl_arg_seq*]=lambda_param_no_default+ '/' ',' { a }
    | a[asdl_arg_seq*]=lambda_param_no_default+ '/' &':' { a }
lambda_slash_with_default[SlashWithDefault*]:
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' ',' { _PyPegen_slash_with_default(p, (asdl_arg_seq *)a, b) }
    | a=lambda_param_no_default* b=lambda_param_with_default+ '/' &':' { _PyPegen_slash_with_default(p, (asdl_arg_seq *)a, b) }

lambda_star_etc[StarEtc*]:
    | '*' a=lambda_param_no_default b=lambda_param_maybe_default* c=[lambda_kwds] {
        _PyPegen_star_etc(p, a, b, c) }
    | '*' ',' b=lambda_param_maybe_default+ c=[lambda_kwds] {
        _PyPegen_star_etc(p, NULL, b, c) }
    | a=lambda_kwds { _PyPegen_star_etc(p, NULL, NULL, a) }
    | invalid_lambda_star_etc

lambda_kwds[arg_ty]: '**' a=lambda_param_no_default { a }

lambda_param_no_default[arg_ty]:
    | a=lambda_param ',' { a }
    | a=lambda_param &':' { a }
lambda_param_with_default[NameDefaultPair*]:
    | a=lambda_param c=default ',' { _PyPegen_name_default_pair(p, a, c, NULL) }
    | a=lambda_param c=default &':' { _PyPegen_name_default_pair(p, a, c, NULL) }
lambda_param_maybe_default[NameDefaultPair*]:
    | a=lambda_param c=default? ',' { _PyPegen_name_default_pair(p, a, c, NULL) }
    | a=lambda_param c=default? &':' { _PyPegen_name_default_pair(p, a, c, NULL) }
lambda_param[arg_ty]: a=NAME { _Py_arg(a->v.Name.id, NULL, NULL, EXTRA) }

disjunction[expr_ty] (memo):
    | a=conjunction b=('or' c=conjunction { c })+ { _Py_BoolOp(
        Or,
        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),
        EXTRA) }
    | conjunction
conjunction[expr_ty] (memo):
    | a=inversion b=('and' c=inversion { c })+ { _Py_BoolOp(
        And,
        CHECK(_PyPegen_seq_insert_in_front(p, a, b)),
        EXTRA) }
    | inversion
inversion[expr_ty] (memo):
    | 'not' a=inversion { ast.UnaryOp(op=ast.Not(), operand=a) }
    | comparison
comparison[expr_ty]:
    | a=bitwise_or b=compare_op_bitwise_or_pair+ {
        _Py_Compare(a, CHECK(_PyPegen_get_cmpops(p, b)), CHECK(_PyPegen_get_exprs(p, b)), EXTRA) }
    | bitwise_or
compare_op_bitwise_or_pair[CmpopExprPair*]:
    | eq_bitwise_or
    | noteq_bitwise_or
    | lte_bitwise_or
    | lt_bitwise_or
    | gte_bitwise_or
    | gt_bitwise_or
    | notin_bitwise_or
    | in_bitwise_or
    | isnot_bitwise_or
    | is_bitwise_or
eq_bitwise_or[CmpopExprPair*]: '==' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Eq, a) }
noteq_bitwise_or[CmpopExprPair*]:
    | (tok='!=' {_PyPegen_check_barry_as_flufl(p) ? NULL : tok}) a=bitwise_or {_PyPegen_cmpop_expr_pair(p, NotEq, a) }
lte_bitwise_or[CmpopExprPair*]: '<=' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, LtE, a) }
lt_bitwise_or[CmpopExprPair*]: '<' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Lt, a) }
gte_bitwise_or[CmpopExprPair*]: '>=' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, GtE, a) }
gt_bitwise_or[CmpopExprPair*]: '>' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Gt, a) }
notin_bitwise_or[CmpopExprPair*]: 'not' 'in' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, NotIn, a) }
in_bitwise_or[CmpopExprPair*]: 'in' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, In, a) }
isnot_bitwise_or[CmpopExprPair*]: 'is' 'not' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, IsNot, a) }
is_bitwise_or[CmpopExprPair*]: 'is' a=bitwise_or { _PyPegen_cmpop_expr_pair(p, Is, a) }

bitwise_or:
    | a=bitwise_or '|' b=bitwise_xor { ast.BinOp(left=a, op=ast.BitOr(), right=b) }
    | bitwise_xor
bitwise_xor:
    | a=bitwise_xor '^' b=bitwise_and { ast.BinOp(left=a, op=ast.BitXor(), right=b) }
    | bitwise_and
bitwise_and:
    | a=bitwise_and '&' b=shift_expr { ast.BinOp(left=a, op=ast.BitAnd(), right=b) }
    | shift_expr
shift_expr:
    | a=shift_expr '<<' b=sum { ast.BinOp(left=a, op=ast.LShift(), right=b) }
    | a=shift_expr '>>' b=sum { ast.BinOp(left=a, op=ast.RShift(), right=b) }
    | sum

sum:
    | a=sum '+' b=term { ast.BinOp(left=a, op=ast.Add(), right=b) }
    | a=sum '-' b=term { ast.BinOp(left=a, op=ast.Sub(), right=b) }
    | term
term[expr_ty]:
    | a=term '*' b=factor { ast.BinOp(left=a, op=ast.Mult(), right=b) }
    | a=term '/' b=factor { ast.BinOp(left=a, op=ast.Div(), right=b) }
    | a=term '//' b=factor { ast.BinOp(left=a, op=ast.FloorDiv(), right=b) }
    | a=term '%' b=factor { ast.BinOp(left=a, op=ast.Mod(), right=b) }
    # XXX
    | a=term '@' b=factor { CHECK_VERSION(5, "The '@' operator is", _Py_BinOp(a, MatMult, b, EXTRA)) }
    | factor
factor[expr_ty] (memo):
    | '+' a=factor { ast.UnaryOp(op=ast.UAdd(), operand=a) }
    | '-' a=factor { ast.UnaryOp(op=ast.USub(), operand=a) }
    | '~' a=factor { ast.UnaryOp(op=ast.Invert(), operand=a) }
    | power
power[expr_ty]:
    | a=await_primary '**' b=factor { ast.BinOp(left=a, op=ast.Pow(), right=b) }
    | await_primary
await_primary[expr_ty] (memo):
    | AWAIT a=primary { CHECK_VERSION(5, "Await expressions are", _Py_Await(a, EXTRA)) }
    | primary
primary[expr_ty]:
    | a=primary '.' b=NAME { ast.Attribute(value=a, attr=b.string, ctx=Load) }
    | a=primary b=genexp { _Py_Call(a, CHECK(_PyPegen_singleton_seq(p, b)), NULL, EXTRA) }
    | a=primary '(' b=[arguments] ')' {
        _Py_Call(a,
                 (b) ? ((expr_ty) b)->v.Call.args : NULL,
                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
                 EXTRA) }
    | a=primary '[' b=slices ']' { ast.Subscript(value=a, slice=b, ctx=Load) }
    | atom

slices[expr_ty]:
    | a=slice !',' { a }
    | a=','.slice+ [','] { ast.Tuple(elts=a, ctx=Load) }
slice[expr_ty]:
    | a=[expression] ':' b=[expression] c=[':' d=[expression] { d }] { ast.Slice(lower=a, upper=b, step=c) }
    | a=expression { a }
atom[expr_ty]:
    | NAME
    | 'True' { ast.NameConstant(True) }
    | 'False' { ast.NameConstant(False) }
    | 'None' { ast.NameConstant(None) }
    | &STRING strings
    | NUMBER
    | &'(' (tuple | group | genexp)
    | &'[' (list | listcomp)
    | &'{' (dict | set | dictcomp | setcomp)
    | '...' { ast.Ellipsis() }

strings[ast.Str] (memo): a=STRING+ { ast.Str(s="".join(a)) }
list[ast.List]:
    | '[' a=[star_named_expressions] ']' { ast.List(elts=a or [], ctx=Load) }
listcomp[ast.ListComp]:
    | '[' a=named_expression ~ b=for_if_clauses ']' { ast.ListComp(elt=a, generators=b) }
    | invalid_comprehension
tuple[ast.Tuple]:
    | '(' a=[y=star_named_expression ',' z=[star_named_expressions] { [y] + z } ] ')' {
        ast.Tuple(elts=a, ctx=Load) }
group:
    | '(' a=(yield_expr | named_expression) ')' { a }
    | invalid_group
genexp[ast.GeneratorExp]:
    | '(' a=expression ~ b=for_if_clauses ')' { ast.GeneratorExp(elt=a, generators=b) }
    | invalid_comprehension
set[ast.Set]: '{' a=expressions_list '}' { ast.Set(elts=a) }
setcomp[ast.SetComp]:
    | '{' a=expression ~ b=for_if_clauses '}' { ast.SetComp(elt=a, generators=b) }
    | invalid_comprehension
dict[ast.Dict]:
    | '{' a=[double_starred_kvpairs] '}' {
        ast.Dict(keys=[kv[0] for kv in a], values=[kv[1] for kv in a])) }
dictcomp[ast.DictComp]:
    | '{' a=kvpair b=for_if_clauses '}' { ast.DictComp(key=a[0], value=a[1], generators=b) }
    | invalid_dict_comprehension
double_starred_kvpairs[list]: a=','.double_starred_kvpair+ [','] { a }
double_starred_kvpair:
    | '**' a=bitwise_or { (None, a) }
    | kvpair
kvpair[tuple]: a=expression ':' b=expression { (a, b) }
for_if_clauses[List[ast.comprehension]]:
    | a=for_if_clause+ { a }
for_if_clause[ast.comprehension]:
    | ASYNC 'for' a=star_targets 'in' ~ b=disjunction c[asdl_expr_seq*]=('if' z=disjunction { z })* {
        CHECK_VERSION(6, "Async comprehensions are", _Py_comprehension(a, b, c, 1, p->arena)) }
    | 'for' a=star_targets 'in' ~ b=disjunction c=('if' z=disjunction { z })* {
       ast.comprehension(target=a, iter=b, ifs=c) }
    | invalid_for_target

yield_expr:
    | 'yield' 'from' a=expression { ast.YieldFrom(value=a) }
    | 'yield' a=[star_expressions] { ast.Yield(value=a) }

arguments (memo):
    | a=args [','] &')' { a }
    | incorrect_arguments
args[expr_ty]:
    | a[asdl_expr_seq*]=','.(starred_expression | named_expression !'=')+ b=[',' k=kwargs {k}] { _PyPegen_collect_call_seqs(p, a, b, EXTRA) }
    | a=kwargs { _Py_Call(_PyPegen_dummy_name(p),
                          CHECK_NULL_ALLOWED(_PyPegen_seq_extract_starred_exprs(p, a)),
                          CHECK_NULL_ALLOWED(_PyPegen_seq_delete_starred_exprs(p, a)),
                          EXTRA) }
kwargs[asdl_seq*]:
    | a=','.kwarg_or_starred+ ',' b=','.kwarg_or_double_starred+ { _PyPegen_join_sequences(p, a, b) }
    | ','.kwarg_or_starred+
    | ','.kwarg_or_double_starred+
starred_expression[expr_ty]:
    | '*' a=expression { _Py_Starred(a, Load, EXTRA) }
kwarg_or_starred[KeywordOrStarred*]:
    | a=NAME '=' b=expression {
        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, EXTRA)), 1) }
    | a=starred_expression { _PyPegen_keyword_or_starred(p, a, 0) }
    | invalid_kwarg
kwarg_or_double_starred[KeywordOrStarred*]:
    | a=NAME '=' b=expression {
        _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(a->v.Name.id, b, EXTRA)), 1) }
    | '**' a=expression { _PyPegen_keyword_or_starred(p, CHECK(_Py_keyword(NULL, a, EXTRA)), 1) }
    | invalid_kwarg

# NOTE: star_targets may contain *bitwise_or, targets may not.
star_targets:
    | a=star_target !',' { a }
    | a=star_target b=(',' c=star_target { c })* [','] {
        ast.Tuple(elts=[a] + b, ctx=Store) }
star_targets_seq: a=','.star_target+ [','] { a }
star_target (memo):
    | '*' a=(!'*' star_target) {
        ast.Starred(value=self.set_expr_context(a, Store), ctx=Store) }
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subcript(value=a, slice=b, ctx=Store) }
    | star_atom
star_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=star_target ')' { self.set_expr_context(a, Store) }
    | '(' a=[star_targets_seq] ')' { ast.Tuple(elts=a, ctx=Store) }
    | '[' a=[star_targets_seq] ']' {  ast.List(elts=a, ctx=Store) }

single_target:
    | single_subscript_attribute_target
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=single_target ')' { a }
single_subscript_attribute_target:
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Store) }

del_targets: a=','.del_target+ [','] { a }
del_target (memo):
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Del) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Del) }
    | del_t_atom
del_t_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Del) }
    | '(' a=del_target ')' { self.set_expr_context(a, Del) }
    | '(' a=[del_targets] ')' { ast.Tuple(elts=a, ctx=Del) }
    | '[' a=[del_targets] ']' { ast.List(elts=a, ctx=Del) }

targets: a=','.target+ [','] { a }
target (memo):
    | a=t_primary '.' b=NAME !t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Store) }
    | a=t_primary '[' b=slices ']' !t_lookahead { ast.Subscript(value=a, slice=b, ctx=Store) }
    | t_atom
t_primary:
    | a=t_primary '.' b=NAME &t_lookahead { ast.Attribute(value=a, attr=b.string, ctx=Load) }
    | a=t_primary '[' b=slices ']' &t_lookahead { ast.Subscript(value=a, slice=b, ctx=Load) }
    | a=t_primary b=genexp &t_lookahead { _Py_Call(a, CHECK(_PyPegen_singleton_seq(p, b)), NULL, EXTRA) }
    | a=t_primary '(' b=[arguments] ')' &t_lookahead {
        _Py_Call(a,
                 (b) ? ((expr_ty) b)->v.Call.args : NULL,
                 (b) ? ((expr_ty) b)->v.Call.keywords : NULL,
                 EXTRA) }
    | a=atom &t_lookahead { a }
t_lookahead: '(' | '[' | '.'
t_atom:
    | a=NAME { ast.Name(id=a.string, ctx=Store) }
    | '(' a=target ')' { self.set_expr_context(a, Store) }
    | '(' b=[targets] ')' { ast.Tuple(elts=b, ctx=Store) }
    | '[' b=[targets] ']' { ast.List(elts=b, ctx=Store) }


# From here on, there are rules for invalid syntax with specialised error messages
incorrect_arguments:
    | args ',' '*' { RAISE_SYNTAX_ERROR("iterable argument unpacking follows keyword argument unpacking") }
    | a=expression for_if_clauses ',' [args | expression for_if_clauses] {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "Generator expression must be parenthesized") }
    | a=args for_if_clauses { _PyPegen_nonparen_genexp_in_call(p, a) }
    | args ',' a=expression for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "Generator expression must be parenthesized") }
    | a=args ',' args { _PyPegen_arguments_parsing_error(p, a) }
invalid_kwarg:
    | a=expression '=' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a, "expression cannot contain assignment, perhaps you meant \"==\"?") }
invalid_named_expression:
    | a=expression ':=' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a, "cannot use assignment expressions with %s", _PyPegen_get_expr_name(a)) }
invalid_assignment:
    | a=invalid_ann_assign_target ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a,
            "only single target (not %s) can be annotated",
            _PyPegen_get_expr_name(a)
        )}
    | a=star_named_expression ',' star_named_expressions* ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "only single target (not tuple) can be annotated") }
    | a=expression ':' expression {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "illegal target for annotation") }
    | (star_targets '=')* a=star_expressions '=' {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }
    | (star_targets '=')* a=yield_expr '=' { RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "assignment to yield expression not possible") }
    | a=star_expressions augassign (yield_expr | star_expressions) {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(
            a,
            "'%s' is an illegal expression for augmented assignment",
            _PyPegen_get_expr_name(a)
        )}
invalid_ann_assign_target[expr_ty]:
    | list
    | tuple
    | '(' a=invalid_ann_assign_target ')' { a }
invalid_del_stmt:
    | 'del' a=star_expressions {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(DEL_TARGETS, a) }
invalid_block:
    | NEWLINE !INDENT { RAISE_INDENTATION_ERROR("expected an indented block") }
invalid_comprehension:
    | ('[' | '(' | '{') a=starred_expression for_if_clauses {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "iterable unpacking cannot be used in comprehension") }
invalid_dict_comprehension:
    | '{' a='**' bitwise_or for_if_clauses '}' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "dict unpacking cannot be used in dict comprehension") }
invalid_parameters:
    | param_no_default* (slash_with_default | param_with_default+) param_no_default {
        RAISE_SYNTAX_ERROR("non-default argument follows default argument") }
invalid_lambda_parameters:
    | lambda_param_no_default* (lambda_slash_with_default | lambda_param_with_default+) lambda_param_no_default {
        RAISE_SYNTAX_ERROR("non-default argument follows default argument") }
invalid_star_etc:
    | '*' (')' | ',' (')' | '**')) { RAISE_SYNTAX_ERROR("named arguments must follow bare *") }
    | '*' ',' TYPE_COMMENT { RAISE_SYNTAX_ERROR("bare * has associated type comment") }
invalid_lambda_star_etc:
    | '*' (':' | ',' (':' | '**')) { RAISE_SYNTAX_ERROR("named arguments must follow bare *") }
invalid_double_type_comments:
    | TYPE_COMMENT NEWLINE TYPE_COMMENT NEWLINE INDENT {
        RAISE_SYNTAX_ERROR("Cannot have two type comments on def") }
invalid_with_item:
    | expression 'as' a=expression {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(STAR_TARGETS, a) }

invalid_for_target:
    | ASYNC? 'for' a=star_expressions {
        RAISE_SYNTAX_ERROR_INVALID_TARGET(FOR_TARGETS, a) }

invalid_group:
    | '(' a=starred_expression ')' {
        RAISE_SYNTAX_ERROR_KNOWN_LOCATION(a, "can't use starred expression here") }
invalid_import_from_targets:
    | import_from_as_names ',' {
        RAISE_SYNTAX_ERROR("trailing comma not allowed without surrounding parentheses") }
